{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SepideSohrabi/K-fold-Image-Classification/blob/main/PyTprch_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pngt5Y-cuS92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4pYhhQCxGJu"
      },
      "outputs": [],
      "source": [
        "#C:\\Users\\sadma\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
        "  #warnings.warn('An interactive session is already active. This can '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lm9g2cmxGHV",
        "outputId": "08e742ab-27ab-4ace-cb8c-b1c311303878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Make it False if do not intend to use Google Colab and want to train in local machine!!\n",
        "google_colab_flag = True\n",
        "\n",
        "# For training in Google Colab\n",
        "if(google_colab_flag):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !ls\n",
        "    import sys\n",
        "    # This is the path to where in google drive the code is stored!\n",
        "    \n",
        "    root_path = '/content/drive/MyDrive/AmnAzmoonPics/'\n",
        "    sys.path.append(root_path)\n",
        "\n",
        "# For local training\n",
        "else:\n",
        "    root_path = ''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eYBwoBQiwkh8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "image_legal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/Legal/*.png'): #assuming png\n",
        "    im=Image.open(filename)\n",
        "    image_legal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y0EPXGflxhg2"
      },
      "outputs": [],
      "source": [
        "image_ilegal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/iLegal/*.png'): #assuming png\n",
        "    im=Image.open(filename)\n",
        "    image_ilegal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotating the images in image_legal and appending them to the list\n",
        "for i in range (len(image_legal)):\n",
        "  rotated_img = image_legal[i].rotate(90)\n",
        "  image_legal.append(rotated_img)"
      ],
      "metadata": {
        "id": "WlL0ROKgs6CT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotating the images in image_ilegal and appending them to the list\n",
        "for i in range (len(image_ilegal)):\n",
        "  rotated_img = image_ilegal[i].rotate(90)\n",
        "  image_ilegal.append(rotated_img)"
      ],
      "metadata": {
        "id": "d4JtRZ8gvi2z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ilegal[90].size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C9VDdV1y6c9",
        "outputId": "8dbacb7f-33b1-4a13-f988-d9bdc561f0b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2736, 1824)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cropping the images in image_legal and appending them to the list\n",
        "box = (100, 100, 1800, 1500)\n",
        "for i in range (len(image_legal)):\n",
        "  Cropped_img = image_legal[i].crop(box)\n",
        "  image_legal.append(Cropped_img)\n"
      ],
      "metadata": {
        "id": "8z5xBuXVwp1g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Cropping the images in image_ilegal and appending them to the list\n",
        " for i in range (len(image_ilegal)):\n",
        "  Cropped_img = image_ilegal[i].crop(box)\n",
        "  image_ilegal.append(Cropped_img)"
      ],
      "metadata": {
        "id": "6Vsx8dhBwpkM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_legal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dg_4Owks5x1",
        "outputId": "ebacadfa-c5e9-4a7e-b0a6-84149fc2b1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_ilegal[120]"
      ],
      "metadata": {
        "id": "bGxQpIyFvpso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JRyfLh2vqPaW"
      },
      "outputs": [],
      "source": [
        "#for preprocessing \n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([            #[1]\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n",
        "\n",
        "\n",
        "#خط [۱]: در اینجا ما یک تغییر متغیر تعریف می کنیم که ترکیبی از تمام تبدیلات تصویر است که باید روی تصویر ورودی اعمال شود.\n",
        "\n",
        "#خط [۲]: اندازه تصویر را به ۲۵۶ × ۲۵۶ پیکسل تغییر می دهد.\n",
        "\n",
        "#خط [۳]: تصویر را به ۲۲۴ × ۲۲۴ پیکسل از مرکز برش می دهد.\n",
        "\n",
        "#خط [۴]: تصویر را به نوع داده Pythorch Tensor تبدیل می کند.\n",
        "\n",
        "#خط [۵-۷]: با تنظیم میانگین و انحراف معیار آن روی مقادیر مشخص شده ، تصویر را نرمال می کند"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mBYar3QvqRh9"
      },
      "outputs": [],
      "source": [
        "X_iLegal=[]\n",
        "for img in image_ilegal:\n",
        "    transformed_img=transform(img)\n",
        "    X_iLegal.append(transformed_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lDzQUsbJubjl"
      },
      "outputs": [],
      "source": [
        "X_Legal=[]\n",
        "for img in image_legal:\n",
        "  transformed_img=transform(img)\n",
        "  X_Legal.append(transformed_img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import torch \n",
        "# Load the ResNext-WSL model\n",
        "\n",
        "# small size model\n",
        "#model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\n",
        "# medium size\n",
        "model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
        "# large size\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\n",
        "# very large\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\n",
        "# model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "cc345ebf105e4cc1ace8704ddf63cb55",
            "1c8e124b725b48bfb24aa210303302a4",
            "853c59e2206d4f74b09858d7cf265ae7",
            "654337deb6d0444eb874f566ecbd3d18",
            "5c4a6442dcf34f928bd92eb03164079e",
            "9c705330fb19487196f3c2db2512f1c8",
            "b86da614cb544a9faa61d937a212ab97",
            "e1e10a6d0afd43f0b223d4f80fa4aa56",
            "c23be193692646209cd89f926ae76880",
            "6bca3a734f2d49fc926cd330282d82f7",
            "e528d85ea83e449c95a705f8124cdae4"
          ]
        },
        "id": "6yBTWxIqJjT3",
        "outputId": "823c2bb4-e61f-459c-9c20-aafd27a350d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/WSL-Images/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x16-c6f796b0.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/741M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc345ebf105e4cc1ace8704ddf63cb55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the CCN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a convolution neural network\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(24)\n",
        "        self.fc1 = nn.Linear(24*10*10, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.bn1(self.conv1(input)))      \n",
        "        output = F.relu(self.bn2(self.conv2(output)))     \n",
        "        output = self.pool(output)                        \n",
        "        output = F.relu(self.bn4(self.conv4(output)))     \n",
        "        output = F.relu(self.bn5(self.conv5(output)))     \n",
        "        output = output.view(-1, 24*10*10)\n",
        "        output = self.fc1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instantiate a neural network model \n",
        "model = Network()"
      ],
      "metadata": {
        "id": "N6P3333hkSgk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        " \n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "m2h9sWS1k_ku"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model on the training data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./myFirstModel.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy():\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "\n",
        "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            \n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 1000 == 999:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
        "        accuracy = testAccuracy()\n",
        "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy"
      ],
      "metadata": {
        "id": "GwPEKd4FmRUJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Visra_ONnAxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTThwiSanAiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#تصویر ورودی را بارگیری کرده و تبدیلات تصویری را که در بالا مشخص کردیم انجام دهیم#\n",
        "#تصویر را پیش پردازش کرده و دسته ای را برای انتقال از شبکه آماده می کنیم.\n",
        "model.eval()\n",
        "out_Legal=[]\n",
        "for i in range (len(X_Legal)):\n",
        "    batch_t = torch.unsqueeze(X_Legal[i], 0)\n",
        "    out_Legal.append(model(batch_t).detach().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "aSnS13CiJx8P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "37d7e56d-343f-4025-e7d1-06bf7f0f5309"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ec715697f451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Legal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Legal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout_Legal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0e24d66103f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 2400]' is invalid for input of size 269664"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_iLegal=[]\n",
        "for i in range (len(X_iLegal)):\n",
        "    batch_t = torch.unsqueeze(X_iLegal[i], 0)\n",
        "    out_iLegal.append(model(batch_t).detach().numpy())"
      ],
      "metadata": {
        "id": "SerTDcRTqs9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_Legal_array=np.asarray(out_Legal)\n",
        "out_iLegal_array=np.asarray(out_iLegal)"
      ],
      "metadata": {
        "id": "RXCC6g_HvF4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_iLegal_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UTpknyZ6A3h",
        "outputId": "9268ffc9-a2fa-4658-f747-6174856bbe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(232, 1, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.concatenate((out_Legal_array,out_iLegal_array) , axis=0)\n",
        "X_train=np.asarray(X_train)"
      ],
      "metadata": {
        "id": "bK7Ipz4C7oTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=[]\n",
        "for i in range (232):\n",
        "  legal=1\n",
        "  y_train.append(legal)\n",
        "\n",
        "\n",
        "for i in range (232 ):\n",
        "  ilegal=0\n",
        "  y_train.append(ilegal)"
      ],
      "metadata": {
        "id": "1OMIQsHShElb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=np.asarray(y_train)"
      ],
      "metadata": {
        "id": "l5yOVGMXiFXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.squeeze(X_train)"
      ],
      "metadata": {
        "id": "rFFdoDc7BVQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtYwHm91BlPQ",
        "outputId": "cfa5534d-ce8b-4e5b-9831-1ef330c62b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
        "   \n",
        "#hist = model.fit(x_train, y_train, epochs=1000, batch_size=32, \n",
        "                 #validation_data=(x_val, y_val), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "wCorq-DgHou0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train , y_train )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um6HM0LH-eJ2",
        "outputId": "8cc6c867-f813-4b02-d393-18f0213c8958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross-Validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "def cross_validation(model, _X, _y, _cv=5):\n",
        "      '''Function to perform 5 Folds Cross-Validation\n",
        "       Parameters\n",
        "       accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "       ----------\n",
        "      model: Python Class, default=None\n",
        "              This is the machine learning algorithm to be used for training.\n",
        "      _X: array\n",
        "           This is the matrix of features.\n",
        "      _y: array\n",
        "           This is the target variable.\n",
        "      _cv: int, default=5\n",
        "          Determines the number of folds for cross-validation.\n",
        "       Returns\n",
        "       -------\n",
        "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
        "       'recall', 'f1' for both training set and validation set.\n",
        "      '''\n",
        "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "      results = cross_validate(estimator=model,\n",
        "                               X=_X,\n",
        "                               y=_y,\n",
        "                               cv=_cv,\n",
        "                               scoring=_scoring,\n",
        "                               return_train_score=True)\n",
        "      \n",
        "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
        "              \n",
        "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
        "              \"Training Precision scores\": results['train_precision'],\n",
        "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
        "              \"Training Recall scores\": results['train_recall'],\n",
        "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
        "              \"Training F1 scores\": results['train_f1'],\n",
        "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
        "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
        "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
        "              \"Validation Precision scores\": results['test_precision'],\n",
        "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
        "              \"Validation Recall scores\": results['test_recall'],\n",
        "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
        "              \"Validation F1 scores\": results['test_f1'],\n",
        "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
        "              }"
      ],
      "metadata": {
        "id": "HhKIhv4VKJXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation(clf, X_train, y_train, _cv=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb0QMLO9KUu9",
        "outputId": "7fd0c91b-cd9f-4e94-ada3-4fd1953d9476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Training Accuracy scores': array([0.77088949, 0.77897574, 0.7574124 , 0.79245283, 0.77419355]),\n",
              " 'Mean Training Accuracy': 77.47848013216243,\n",
              " 'Training Precision scores': array([0.77173913, 0.74178404, 0.75806452, 0.77114428, 0.73831776]),\n",
              " 'Mean Training Precision': 0.7562099439477622,\n",
              " 'Training Recall scores': array([0.76756757, 0.85405405, 0.75806452, 0.83333333, 0.84946237]),\n",
              " 'Mean Training Recall': 0.812496367335077,\n",
              " 'Training F1 scores': array([0.7696477 , 0.79396985, 0.75806452, 0.80103359, 0.79      ]),\n",
              " 'Mean Training F1 Score': 0.7825431307166989,\n",
              " 'Validation Accuracy scores': array([0.67741935, 0.74193548, 0.7311828 , 0.55913978, 0.64130435]),\n",
              " 'Mean Validation Accuracy': 67.01963534361852,\n",
              " 'Validation Precision scores': array([0.9047619 , 0.84848485, 0.78378378, 0.53846154, 0.5915493 ]),\n",
              " 'Mean Validation Precision': 0.7334082742533446,\n",
              " 'Validation Recall scores': array([0.40425532, 0.59574468, 0.63043478, 0.76086957, 0.91304348]),\n",
              " 'Mean Validation Recall': 0.6608695652173913,\n",
              " 'Validation F1 scores': array([0.55882353, 0.7       , 0.69879518, 0.63063063, 0.71794872]),\n",
              " 'Mean Validation F1 Score': 0.6612396117428009}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GridSearchCV(model, parameters,\n",
        "                         fit_params={'early_stopping_rounds':20,\\\n",
        "                         'eval_set':[(X,y)]},cv=kfold)"
      ],
      "metadata": {
        "id": "Zx5QfKmJip1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the Training set results\n",
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_train, y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
        "plt.title('Kernel SVM (Training set)')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yi9vRmDbnPUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped Bar Chart for both training and validation data\n",
        "def plot_result(x_label, y_label, plot_title, train_data, val_data):\n",
        "        '''Function to plot a grouped bar chart showing the training and validation\n",
        "          results of the ML model in each fold after applying K-fold cross-validation.\n",
        "         Parameters\n",
        "         ----------\n",
        "         x_label: str, \n",
        "            Name of the algorithm used for training e.g 'Decision Tree'\n",
        "          \n",
        "         y_label: str, \n",
        "            Name of metric being visualized e.g 'Accuracy'\n",
        "         plot_title: str, \n",
        "            This is the title of the plot e.g 'Accuracy Plot'\n",
        "         \n",
        "         train_result: list, array\n",
        "            This is the list containing either training precision, accuracy, or f1 score.\n",
        "        \n",
        "         val_result: list, array\n",
        "            This is the list containing either validation precision, accuracy, or f1 score.\n",
        "         Returns\n",
        "         -------\n",
        "         The function returns a Grouped Barchart showing the training and validation result\n",
        "         in each fold.\n",
        "        '''\n",
        "        \n",
        "        # Set size of plot\n",
        "        plt.figure(figsize=(12,6))\n",
        "        labels = [\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\"]\n",
        "        X_axis = np.arange(len(labels))\n",
        "        ax = plt.gca()\n",
        "        plt.ylim(0.40000, 1)\n",
        "        plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')\n",
        "        plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')\n",
        "        plt.title(plot_title, fontsize=30)\n",
        "        plt.xticks(X_axis, labels)\n",
        "        plt.xlabel(x_label, fontsize=14)\n",
        "        plt.ylabel(y_label, fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "I-rgyJVwL6q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeX0LaQQxGBw"
      },
      "outputs": [],
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Based on the split ratio this function moves some portion of the source folder to destination folder!\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest locaiton\n",
        "\n",
        "    \"\"\"\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Transfer the files from source to dest for all the classes. This function calls the 'transfer_between_folders' to actually perform the transfer.\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest locaiton\n",
        "\n",
        "    \"\"\"\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculate accuracy, precision, and f1 score of the model's prediction with respect to true labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: list/array\n",
        "                All true class labels\n",
        "            y_pred: list/array\n",
        "                All predicted class labels\n",
        "\n",
        "        Returns:\n",
        "            accuracy: float\n",
        "                Accuracy measure of the model\n",
        "            precision: float\n",
        "                Precision measure of the model\n",
        "            f1_Score: float\n",
        "                F1-score measure of the model\n",
        "\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf4WM-eFxF-3"
      },
      "outputs": [],
      "source": [
        "#First, check if test folder is empty or not, if not transfer all existing files to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJDfo5DuxF70",
        "outputId": "9a0ce68a-6076-4ddb-957a-2c333ad1a247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n"
          ]
        }
      ],
      "source": [
        "transfer_all_class_between_folders('test', 'train', 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5zvfSlwxF5N"
      },
      "outputs": [],
      "source": [
        "#Now, split some part of train data into the test folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3hQXBNIxF2x"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qEvzonFxFz4"
      },
      "outputs": [],
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    \"\"\" Prepare the file names (X) and the class labels (Y) from folder location of images.\n",
        "\n",
        "        Args:\n",
        "            folder_name: str\n",
        "                Source folder's path\n",
        "\n",
        "    \"\"\"\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xbtAdgNxFw9"
      },
      "outputs": [],
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTWVq7vNxFuF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHopGeAnxFrU"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "epoch = 100 #اینجا رو از صد گذاشتم ده که زمان نگیره \n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj5xE-VdxFoa"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Note that, this model structure is a very basic one. \n",
        "    To achieve better performance, you should change the model structure and hyperparameters according to your needs and data. \n",
        "    So, optimize the structure of the model!\n",
        "\"\"\"\n",
        "\n",
        "def get_model():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(32, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(16, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT7Q9KHMynAK"
      },
      "outputs": [],
      "source": [
        "#Stratified K-Fold Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNETGAHGyTtP",
        "outputId": "8878a6a0-ca68-4414-e457-2897f66db826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Found 62 images belonging to 2 classes.\n",
            "Found 32 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.6921 - accuracy: 0.4839\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6985 - accuracy: 0.5484\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6937 - accuracy: 0.5484\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6864 - accuracy: 0.5323\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.7017 - accuracy: 0.5161\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.7056 - accuracy: 0.4839\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.6956 - accuracy: 0.5323\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6864 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.7057 - accuracy: 0.4516\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6858 - accuracy: 0.5323\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6876 - accuracy: 0.5806\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6845 - accuracy: 0.5484\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6879 - accuracy: 0.5323\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6864 - accuracy: 0.5323\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6931 - accuracy: 0.4839\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6870 - accuracy: 0.5806\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6783 - accuracy: 0.5484\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6933 - accuracy: 0.5968\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6802 - accuracy: 0.5323\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6586 - accuracy: 0.5645\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6594 - accuracy: 0.6129\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.6694 - accuracy: 0.5484\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6424 - accuracy: 0.6774\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.7086 - accuracy: 0.4677\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6890 - accuracy: 0.5161\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6590 - accuracy: 0.6452\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.6505 - accuracy: 0.6129\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5991 - accuracy: 0.8226\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6291 - accuracy: 0.6613\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6263 - accuracy: 0.6935\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6028 - accuracy: 0.6129\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5749 - accuracy: 0.7581\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5323 - accuracy: 0.7581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5549 - accuracy: 0.6935\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5506 - accuracy: 0.6935\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6568 - accuracy: 0.6613\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5364 - accuracy: 0.7419\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5625 - accuracy: 0.6774\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4891 - accuracy: 0.7581\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5947 - accuracy: 0.6613\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5648 - accuracy: 0.7097\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5131 - accuracy: 0.7581\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5062 - accuracy: 0.7742\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5336 - accuracy: 0.7742\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4994 - accuracy: 0.7097\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4489 - accuracy: 0.7581\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4893 - accuracy: 0.7258\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5108 - accuracy: 0.7903\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4323 - accuracy: 0.8226\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4332 - accuracy: 0.8226\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5626 - accuracy: 0.7097\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3893 - accuracy: 0.8387\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4774 - accuracy: 0.7903\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4210 - accuracy: 0.8226\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4402 - accuracy: 0.7903\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5960 - accuracy: 0.7419\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4136 - accuracy: 0.8871\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4641 - accuracy: 0.7742\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4320 - accuracy: 0.7742\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4128 - accuracy: 0.8226\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4725 - accuracy: 0.7419\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5874 - accuracy: 0.7258\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4078 - accuracy: 0.8387\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.4502 - accuracy: 0.8226\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4454 - accuracy: 0.7903\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4159 - accuracy: 0.7742\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4518 - accuracy: 0.7903\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3996 - accuracy: 0.8387\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4275 - accuracy: 0.8065\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4054 - accuracy: 0.8065\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4251 - accuracy: 0.7742\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3915 - accuracy: 0.8065\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4459 - accuracy: 0.7742\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4141 - accuracy: 0.8387\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4303 - accuracy: 0.7903\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3121 - accuracy: 0.9032\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2806 - accuracy: 0.9194\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3315 - accuracy: 0.9032\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2794 - accuracy: 0.8548\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.2874 - accuracy: 0.8871\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3373 - accuracy: 0.8387\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.2896 - accuracy: 0.9194\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3944 - accuracy: 0.7419\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3103 - accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3280 - accuracy: 0.8710\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3559 - accuracy: 0.8710\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3054 - accuracy: 0.8548\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4360 - accuracy: 0.8548\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2464 - accuracy: 0.8871\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3398 - accuracy: 0.8548\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3620 - accuracy: 0.8065\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3100 - accuracy: 0.8710\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3393 - accuracy: 0.8548\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3181 - accuracy: 0.8871\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3365 - accuracy: 0.8548\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3188 - accuracy: 0.8548\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2740 - accuracy: 0.8871\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2936 - accuracy: 0.8710\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2963 - accuracy: 0.8548\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.25\n",
            "Precision : 0.18181818181818182\n",
            "f1Score : 0.2105263157894737\n",
            "[[ 0  0  0]\n",
            " [ 8  8  0]\n",
            " [ 2 14  0]]\n",
            "Results for fold 2\n",
            "Found 63 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 31 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5616 - accuracy: 0.7619\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4981 - accuracy: 0.8095\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6409 - accuracy: 0.7619\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5410 - accuracy: 0.7937\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5188 - accuracy: 0.7619\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5974 - accuracy: 0.7143\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4689 - accuracy: 0.7937\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.4710 - accuracy: 0.8095\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4918 - accuracy: 0.7619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4937 - accuracy: 0.7302\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4828 - accuracy: 0.7460\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4953 - accuracy: 0.7460\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4927 - accuracy: 0.7778\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.4701 - accuracy: 0.8095\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4909 - accuracy: 0.7302\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4867 - accuracy: 0.7619\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4408 - accuracy: 0.7937\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4840 - accuracy: 0.7778\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4453 - accuracy: 0.7778\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3934 - accuracy: 0.8095\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4367 - accuracy: 0.7778\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4319 - accuracy: 0.7937\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4616 - accuracy: 0.7937\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4702 - accuracy: 0.7619\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4325 - accuracy: 0.7778\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4231 - accuracy: 0.8254\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4567 - accuracy: 0.7937\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3606 - accuracy: 0.8254\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3872 - accuracy: 0.8095\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4482 - accuracy: 0.7778\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3860 - accuracy: 0.7937\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4027 - accuracy: 0.7937\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4493 - accuracy: 0.7778\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4217 - accuracy: 0.7937\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3858 - accuracy: 0.7937\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.3801 - accuracy: 0.7937\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3894 - accuracy: 0.8095\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3756 - accuracy: 0.8413\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3775 - accuracy: 0.8095\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3302 - accuracy: 0.8413\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3623 - accuracy: 0.8254\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3003 - accuracy: 0.8571\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3581 - accuracy: 0.7778\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3799 - accuracy: 0.8254\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3833 - accuracy: 0.8095\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3420 - accuracy: 0.8254\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3640 - accuracy: 0.8095\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3119 - accuracy: 0.8571\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3448 - accuracy: 0.8254\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3797 - accuracy: 0.8254\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3430 - accuracy: 0.7778\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.3658 - accuracy: 0.8095\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3523 - accuracy: 0.8095\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3196 - accuracy: 0.8571\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3244 - accuracy: 0.8413\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3711 - accuracy: 0.7937\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2853 - accuracy: 0.8413\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3224 - accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3180 - accuracy: 0.8254\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3369 - accuracy: 0.8095\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3018 - accuracy: 0.8254\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3207 - accuracy: 0.8413\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2857 - accuracy: 0.8571\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3344 - accuracy: 0.8254\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3648 - accuracy: 0.8095\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3762 - accuracy: 0.7937\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3258 - accuracy: 0.8254\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3050 - accuracy: 0.8571\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3059 - accuracy: 0.8254\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3209 - accuracy: 0.7778\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3353 - accuracy: 0.8413\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3023 - accuracy: 0.8413\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2589 - accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.2971 - accuracy: 0.9048\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2809 - accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3260 - accuracy: 0.8254\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2596 - accuracy: 0.8889\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2692 - accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2770 - accuracy: 0.8730\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.2628 - accuracy: 0.8730\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3462 - accuracy: 0.8095\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2817 - accuracy: 0.8413\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2475 - accuracy: 0.8571\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2899 - accuracy: 0.8730\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2397 - accuracy: 0.8730\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4010 - accuracy: 0.8254\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3493 - accuracy: 0.8413\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2941 - accuracy: 0.8413\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3003 - accuracy: 0.8571\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3126 - accuracy: 0.8730\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2952 - accuracy: 0.8413\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2521 - accuracy: 0.8889\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2637 - accuracy: 0.8730\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2412 - accuracy: 0.8730\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.2549 - accuracy: 0.8571\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2660 - accuracy: 0.8571\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2970 - accuracy: 0.8571\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2624 - accuracy: 0.8571\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2385 - accuracy: 0.9048\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2803 - accuracy: 0.8730\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.0967741935483871\n",
            "Precision : 0.1032258064516129\n",
            "f1Score : 0.09989594172736734\n",
            "[[ 0  0  0]\n",
            " [13  3  0]\n",
            " [ 3 12  0]]\n",
            "Results for fold 3\n",
            "Found 63 images belonging to 2 classes.\n",
            "Found 31 images belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4515 - accuracy: 0.8254\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3354 - accuracy: 0.8413\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3613 - accuracy: 0.8095\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3259 - accuracy: 0.8413\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3343 - accuracy: 0.8254\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3979 - accuracy: 0.7460\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2864 - accuracy: 0.8254\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2921 - accuracy: 0.8730\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3631 - accuracy: 0.8571\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3650 - accuracy: 0.8254\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2727 - accuracy: 0.8730\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2439 - accuracy: 0.8571\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3214 - accuracy: 0.8413\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2680 - accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2688 - accuracy: 0.8571\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3285 - accuracy: 0.8413\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3762 - accuracy: 0.8095\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3094 - accuracy: 0.8254\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3088 - accuracy: 0.9048\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3725 - accuracy: 0.8413\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3115 - accuracy: 0.8413\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3405 - accuracy: 0.8254\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3704 - accuracy: 0.8095\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.3623 - accuracy: 0.7937\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3415 - accuracy: 0.8254\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3069 - accuracy: 0.8254\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3649 - accuracy: 0.8095\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2870 - accuracy: 0.8571\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2643 - accuracy: 0.8730\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3089 - accuracy: 0.8413\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2857 - accuracy: 0.8254\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2516 - accuracy: 0.8571\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3029 - accuracy: 0.8413\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2831 - accuracy: 0.8413\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3212 - accuracy: 0.8413\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2944 - accuracy: 0.8413\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2524 - accuracy: 0.8730\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2519 - accuracy: 0.8730\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2968 - accuracy: 0.8730\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2673 - accuracy: 0.8413\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.2420 - accuracy: 0.8730\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2434 - accuracy: 0.8730\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2580 - accuracy: 0.8571\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2625 - accuracy: 0.8254\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3107 - accuracy: 0.8413\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2413 - accuracy: 0.8889\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.2520 - accuracy: 0.8889\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2629 - accuracy: 0.8571\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2132 - accuracy: 0.9206\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2016 - accuracy: 0.8730\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2913 - accuracy: 0.8730\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1973 - accuracy: 0.8889\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2487 - accuracy: 0.8571\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2956 - accuracy: 0.8413\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1947 - accuracy: 0.9365\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2242 - accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2079 - accuracy: 0.8889\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3535 - accuracy: 0.8889\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1806 - accuracy: 0.9365\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2135 - accuracy: 0.8889\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2766 - accuracy: 0.8571\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2265 - accuracy: 0.9048\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1875 - accuracy: 0.9048\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.2371 - accuracy: 0.9206\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2060 - accuracy: 0.9048\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1671 - accuracy: 0.9206\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2141 - accuracy: 0.9048\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1679 - accuracy: 0.9048\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.1702 - accuracy: 0.9206\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2216 - accuracy: 0.8889\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1508 - accuracy: 0.9524\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1897 - accuracy: 0.9365\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1654 - accuracy: 0.9048\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1667 - accuracy: 0.9365\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2479 - accuracy: 0.8730\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2623 - accuracy: 0.8730\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1850 - accuracy: 0.9048\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1958 - accuracy: 0.9206\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2160 - accuracy: 0.9206\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2938 - accuracy: 0.8889\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2378 - accuracy: 0.8889\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2773 - accuracy: 0.8571\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1896 - accuracy: 0.9365\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2265 - accuracy: 0.9206\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.2411 - accuracy: 0.8889\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4702 - accuracy: 0.8730\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2393 - accuracy: 0.9048\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2671 - accuracy: 0.8730\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2298 - accuracy: 0.8571\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.2154 - accuracy: 0.8571\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1218 - accuracy: 0.9524\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2091 - accuracy: 0.8730\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1987 - accuracy: 0.9048\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1452 - accuracy: 0.9365\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1609 - accuracy: 0.9206\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1690 - accuracy: 0.9206\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1896 - accuracy: 0.8730\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2003 - accuracy: 0.9206\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1710 - accuracy: 0.9365\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.1634 - accuracy: 0.9206\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.0\n",
            "Precision : 0.0\n",
            "f1Score : 0.0\n",
            "[[ 0  0  0]\n",
            " [15  0  0]\n",
            " [ 3 13  0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train', 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "    \n",
        "    # fit model\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=epoch)\n",
        "\n",
        "    predictions = model.predict(validation_generator, verbose=1)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    \n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")\n",
        "    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNjDxwT7TiqT",
        "outputId": "60ae53fc-fdf2-4589-d9eb-4b10b61428b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# save the model to disk\n",
        "import pickle\n",
        "filename = 'finalized_model.h5'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "eMznso5qXvXy",
        "outputId": "59b98d70-622b-4c3e-c6de-25290ceb75b9"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-97-2a6002e52a59>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ],
      "source": [
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "#loaded_model = pickle.load(open(filename, 'rb'))\n",
        "#result = loaded_model.score(X_test, Y_test)\n",
        "#print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvov141JHbRV"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5t5Y9AqEkEb"
      },
      "outputs": [],
      "source": [
        "img = (cv2.imread(\"/content/8.png\"))/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfEB3rbtIGcK"
      },
      "outputs": [],
      "source": [
        "img = np.resize(img ,(1,100,100,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkBZINmLym7A",
        "outputId": "22a2e858-0c18-4dad-cc83-d39b87c385b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.19827849, 0.8017215 ]], dtype=float32)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19-wZI_Zx1iLcSuR2ib1PXmvv2WTTLaPp",
      "authorship_tag": "ABX9TyPCJ0MmhM3pusUT2sdsOkhR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc345ebf105e4cc1ace8704ddf63cb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c8e124b725b48bfb24aa210303302a4",
              "IPY_MODEL_853c59e2206d4f74b09858d7cf265ae7",
              "IPY_MODEL_654337deb6d0444eb874f566ecbd3d18"
            ],
            "layout": "IPY_MODEL_5c4a6442dcf34f928bd92eb03164079e"
          }
        },
        "1c8e124b725b48bfb24aa210303302a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c705330fb19487196f3c2db2512f1c8",
            "placeholder": "​",
            "style": "IPY_MODEL_b86da614cb544a9faa61d937a212ab97",
            "value": "100%"
          }
        },
        "853c59e2206d4f74b09858d7cf265ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1e10a6d0afd43f0b223d4f80fa4aa56",
            "max": 777518664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c23be193692646209cd89f926ae76880",
            "value": 777518664
          }
        },
        "654337deb6d0444eb874f566ecbd3d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bca3a734f2d49fc926cd330282d82f7",
            "placeholder": "​",
            "style": "IPY_MODEL_e528d85ea83e449c95a705f8124cdae4",
            "value": " 741M/741M [00:20&lt;00:00, 134MB/s]"
          }
        },
        "5c4a6442dcf34f928bd92eb03164079e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c705330fb19487196f3c2db2512f1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86da614cb544a9faa61d937a212ab97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e10a6d0afd43f0b223d4f80fa4aa56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23be193692646209cd89f926ae76880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bca3a734f2d49fc926cd330282d82f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e528d85ea83e449c95a705f8124cdae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}