{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SepideSohrabi/K-fold-Image-Classification/blob/main/2th_customized_k_fold_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pngt5Y-cuS92"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lm9g2cmxGHV",
        "outputId": "4cd9790e-bd3a-4240-a77d-72af1cd0f386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "\n",
        "# Make it False if do not intend to use Google Colab and want to train in local machine!!\n",
        "google_colab_flag = True\n",
        "\n",
        "# For training in Google Colab\n",
        "if(google_colab_flag):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !ls\n",
        "    import sys\n",
        "    # This is the path to where in google drive the code is stored!\n",
        "    \n",
        "    root_path = '/content/drive/MyDrive/AmnAzmoonPics/'\n",
        "    sys.path.append(root_path)\n",
        "\n",
        "# For local training\n",
        "else:\n",
        "    root_path = ''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eYBwoBQiwkh8"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "from PIL import Image\n",
        "import glob\n",
        "image_legal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/DS/train/Legal/*.png'): #assuming gif\n",
        "    im=Image.open(filename)\n",
        "    image_legal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y0EPXGflxhg2"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "image_ilegal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/DS/train/iLegal/*.png'): #assuming gif\n",
        "    im=Image.open(filename)\n",
        "    image_ilegal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#5\n",
        "#for preprocessing \n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([            #[1]\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#6\n",
        "X_iLegal=[]\n",
        "for img in image_ilegal:\n",
        "    transformed_img=transform(img)\n",
        "    X_iLegal.append(transformed_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#7\n",
        "X_Legal=[]\n",
        "for img in image_legal:\n",
        "  transformed_img=transform(img)\n",
        "  X_Legal.append(transformed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#8\n",
        "import torch \n",
        "# Load the ResNext-WSL model\n",
        "\n",
        "# small size model\n",
        "#model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\n",
        "# medium size\n",
        "model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
        "# large size\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\n",
        "# very large\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#9\n",
        "model.eval()\n",
        "out_Legal=[]\n",
        "for i in range (len(X_Legal)):\n",
        "    batch_t = torch.unsqueeze(X_Legal[i], 0)\n",
        "    out_Legal.append(model(batch_t).detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#10\n",
        "out_iLegal=[]\n",
        "for i in range (len(X_iLegal)):\n",
        "    batch_t = torch.unsqueeze(X_iLegal[i], 0)\n",
        "    out_iLegal.append(model(batch_t).detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#11\n",
        "out_Legal_array=np.asarray(out_Legal)\n",
        "out_iLegal_array=np.asarray(out_iLegal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#12\n",
        "X_train=np.concatenate((out_Legal_array,out_iLegal_array) , axis=0)\n",
        "X_train=np.asarray(X_train)\n",
        "X_train=np.squeeze(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#13\n",
        "#1 refers to legal class and 0 refers to ilegal class\n",
        "y_train=[]\n",
        "for i in range (45):\n",
        "  legal=1\n",
        "  y_train.append(legal)\n",
        "\n",
        "\n",
        "for i in range (46 ):\n",
        "  ilegal=0\n",
        "  y_train.append(ilegal)\n",
        "\n",
        "y_train=np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train , y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPzOLY0GhgCwxLxd6qxZhBL",
      "include_colab_link": true,
      "mount_file_id": "19-wZI_Zx1iLcSuR2ib1PXmvv2WTTLaPp",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
