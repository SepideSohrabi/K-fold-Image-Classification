{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SepideSohrabi/K-fold-Image-Classification/blob/main/2th_customized_k_fold_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pngt5Y-cuS92"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lm9g2cmxGHV",
        "outputId": "4cd9790e-bd3a-4240-a77d-72af1cd0f386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "\n",
        "# Make it False if do not intend to use Google Colab and want to train in local machine!!\n",
        "google_colab_flag = True\n",
        "\n",
        "# For training in Google Colab\n",
        "if(google_colab_flag):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !ls\n",
        "    import sys\n",
        "    # This is the path to where in google drive the code is stored!\n",
        "    \n",
        "    root_path = '/content/drive/MyDrive/AmnAzmoonPics/'\n",
        "    sys.path.append(root_path)\n",
        "\n",
        "# For local training\n",
        "else:\n",
        "    root_path = ''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eYBwoBQiwkh8"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "from PIL import Image\n",
        "import glob\n",
        "image_legal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/Legal/*.png'): #assuming gif\n",
        "    im=Image.open(filename)\n",
        "    image_legal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y0EPXGflxhg2"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "image_ilegal = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/AmnAzmoonPics/iLegal/*.png'): #assuming gif\n",
        "    im=Image.open(filename)\n",
        "    image_ilegal.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#5\n",
        "#for preprocessing \n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([            #[1]\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#6\n",
        "X_iLegal=[]\n",
        "for img in image_ilegal:\n",
        "    transformed_img=transform(img)\n",
        "    X_iLegal.append(transformed_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#7\n",
        "X_Legal=[]\n",
        "for img in image_legal:\n",
        "  transformed_img=transform(img)\n",
        "  X_Legal.append(transformed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#8\n",
        "import torch \n",
        "# Load the ResNext-WSL model\n",
        "\n",
        "# small size model\n",
        "#model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\n",
        "# medium size\n",
        "model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
        "# large size\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x32d_wsl')\n",
        "# very large\n",
        "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x48d_wsl')\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#9\n",
        "model.eval()\n",
        "out_Legal=[]\n",
        "for i in range (len(X_Legal)):\n",
        "    batch_t = torch.unsqueeze(X_Legal[i], 0)\n",
        "    out_Legal.append(model(batch_t).detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#10\n",
        "out_iLegal=[]\n",
        "for i in range (len(X_iLegal)):\n",
        "    batch_t = torch.unsqueeze(X_iLegal[i], 0)\n",
        "    out_iLegal.append(model(batch_t).detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#11\n",
        "out_Legal_array=np.asarray(out_Legal)\n",
        "out_iLegal_array=np.asarray(out_iLegal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#12\n",
        "X_train=np.concatenate((out_Legal_array,out_iLegal_array) , axis=0)\n",
        "X_train=np.asarray(X_train)\n",
        "X_train=np.squeeze(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#13\n",
        "#1 refers to legal class and 0 refers to ilegal class\n",
        "y_train=[]\n",
        "for i in range (45):\n",
        "  legal=1\n",
        "  y_train.append(legal)\n",
        "\n",
        "\n",
        "for i in range (46 ):\n",
        "  ilegal=0\n",
        "  y_train.append(ilegal)\n",
        "\n",
        "y_train=np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#14\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#15\n",
        "# K-Fold Cross-Validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "def cross_validation(model, _X, _y, _cv=5):\n",
        "      '''Function to perform 5 Folds Cross-Validation\n",
        "       Parameters\n",
        "       ----------\n",
        "      model: Python Class, default=None\n",
        "              This is the machine learning algorithm to be used for training.\n",
        "      _X: array\n",
        "           This is the matrix of features.\n",
        "      _y: array\n",
        "           This is the target variable.\n",
        "      _cv: int, default=5\n",
        "          Determines the number of folds for cross-validation.\n",
        "       Returns\n",
        "       -------\n",
        "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
        "       'recall', 'f1' for both training set and validation set.\n",
        "      '''\n",
        "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "      results = cross_validate(estimator=model,\n",
        "                               X=_X,\n",
        "                               y=_y,\n",
        "                               cv=_cv,\n",
        "                               scoring=_scoring,\n",
        "                               return_train_score=True)\n",
        "      \n",
        "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
        "              \n",
        "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
        "              \"Training Precision scores\": results['train_precision'],\n",
        "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
        "              \"Training Recall scores\": results['train_recall'],\n",
        "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
        "              \"Training F1 scores\": results['train_f1'],\n",
        "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
        "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
        "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
        "              \"Validation Precision scores\": results['test_precision'],\n",
        "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
        "              \"Validation Recall scores\": results['test_recall'],\n",
        "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
        "              \"Validation F1 scores\": results['test_f1'],\n",
        "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#16\n",
        "cross_validation(clf, X_train, y_train, _cv=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPzOLY0GhgCwxLxd6qxZhBL",
      "include_colab_link": true,
      "mount_file_id": "19-wZI_Zx1iLcSuR2ib1PXmvv2WTTLaPp",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
